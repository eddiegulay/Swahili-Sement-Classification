{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZ7fwS955xdetzOGMoXgPt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eddiegulay/Swahili-Sement-Classification/blob/main/ASRmzizima.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nD7NcrG1VktA"
      },
      "outputs": [],
      "source": [
        "!pip install pandas numpy tensorflow==2.10.0 tensorflow-io==0.27.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NegqPr_CXDHm",
        "outputId": "245cfd0f-f82e-4e2d-b92f-3b1bb1c1e8c3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/eddiegulay/Swahili-transcription.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGXS-MfeVyB3",
        "outputId": "3669b767-3378-49d6-9666-bd8087a9316c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Swahili-transcription'...\n",
            "remote: Enumerating objects: 22282, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 22282 (delta 0), reused 3 (delta 0), pack-reused 22279\u001b[K\n",
            "Receiving objects: 100% (22282/22282), 651.71 MiB | 22.31 MiB/s, done.\n",
            "Resolving deltas: 100% (21/21), done.\n",
            "Updating files: 100% (22267/22267), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import tensorflow_io as tfio\n",
        "\n",
        "from pydub import AudioSegment\n",
        "import io"
      ],
      "metadata": {
        "id": "wt9VHEpQWx0b"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_file_path = \"Swahili-transcription/data/train_audios/\"\n",
        "test_file_path = \"Swahili-transcription/data/test_audios/\"\n",
        "\n",
        "train_dataset = \"Swahili-transcription/train.csv\"\n",
        "test_dataset = \"Swahili-transcription/test.csv\""
      ],
      "metadata": {
        "id": "RP2sMhQiWz19"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(train_dataset)\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "EXVEj7TWW4Ey",
        "outputId": "d43c3cb4-16df-4011-a481-53e8fc449d49"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         audio_ID                path  \\\n",
              "0  audio_faa7312a  audio_faa7312a.mp3   \n",
              "1  audio_643a10c1  audio_643a10c1.mp3   \n",
              "2  audio_5b626e74  audio_5b626e74.mp3   \n",
              "3  audio_5972c5f3  audio_5972c5f3.mp3   \n",
              "4  audio_deebd5b0  audio_deebd5b0.mp3   \n",
              "\n",
              "                                            sentence  \n",
              "0                     huko kwa Wakiroba Mkoa wa Mara  \n",
              "1  Alingaa katika medani za kisiasa na uongozi nd...  \n",
              "2               Vitu saba ambavyo kila baba atakuwa.  \n",
              "3  inaonyesha mawaziri wapya ambao wamechukua naf...  \n",
              "4                ee hii pia inatumiwa na kiwanda cha  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ce4d3c2-7e6f-4a8a-8b07-5f1a2d71c65a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>audio_ID</th>\n",
              "      <th>path</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>audio_faa7312a</td>\n",
              "      <td>audio_faa7312a.mp3</td>\n",
              "      <td>huko kwa Wakiroba Mkoa wa Mara</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>audio_643a10c1</td>\n",
              "      <td>audio_643a10c1.mp3</td>\n",
              "      <td>Alingaa katika medani za kisiasa na uongozi nd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>audio_5b626e74</td>\n",
              "      <td>audio_5b626e74.mp3</td>\n",
              "      <td>Vitu saba ambavyo kila baba atakuwa.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>audio_5972c5f3</td>\n",
              "      <td>audio_5972c5f3.mp3</td>\n",
              "      <td>inaonyesha mawaziri wapya ambao wamechukua naf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>audio_deebd5b0</td>\n",
              "      <td>audio_deebd5b0.mp3</td>\n",
              "      <td>ee hii pia inatumiwa na kiwanda cha</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ce4d3c2-7e6f-4a8a-8b07-5f1a2d71c65a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8ce4d3c2-7e6f-4a8a-8b07-5f1a2d71c65a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8ce4d3c2-7e6f-4a8a-8b07-5f1a2d71c65a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d43722b8-e8dc-41c4-a99b-b9f12389a84e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d43722b8-e8dc-41c4-a99b-b9f12389a84e')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d43722b8-e8dc-41c4-a99b-b9f12389a84e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv(test_dataset)\n",
        "test_df.columns.to_list()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lhenlBHW6b2",
        "outputId": "969ed61b-e542-438d-b90b-5c6862989b56"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['audio_ID', 'path']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_df = train_df[:500]\n",
        "# test_df = test_df[:500]"
      ],
      "metadata": {
        "id": "OQ2zb18PW8IJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import concurrent.futures\n",
        "\n",
        "train_audio_path = \"Swahili-transcription/data/train_audios/\"\n",
        "train_wav_path = \"Swahili-transcription/data/train_wavs/\"\n",
        "\n",
        "# Create the train_wavs directory if it doesn't exist\n",
        "os.makedirs(train_wav_path, exist_ok=True)\n",
        "\n",
        "\n",
        "def convert_mp3_to_wav(mp3_path, wav_path):\n",
        "    audio = AudioSegment.from_mp3(mp3_path)\n",
        "    audio = audio.set_channels(1)  # Convert to mono\n",
        "    audio = audio.set_frame_rate(16000)  # Resample to 16kHz\n",
        "    audio.export(wav_path, format=\"wav\")\n",
        "\n",
        "# Set the maximum number of threads\n",
        "max_threads = 1000\n",
        "\n",
        "with concurrent.futures.ThreadPoolExecutor(max_workers=max_threads) as executor:\n",
        "    futures = []\n",
        "\n",
        "    for index, row in train_df.iterrows():\n",
        "        filename = row['path']\n",
        "        if filename.endswith(\".mp3\"):\n",
        "            mp3_path = os.path.join(train_audio_path, filename)\n",
        "            wav_filename = filename.replace(\".mp3\", \".wav\")\n",
        "            wav_path = os.path.join(train_wav_path, wav_filename)\n",
        "\n",
        "            future = executor.submit(convert_mp3_to_wav, mp3_path, wav_path)\n",
        "            futures.append(future)\n",
        "\n",
        "    # Wait for all threads to finish\n",
        "    concurrent.futures.wait(futures)\n",
        "\n",
        "print(\"Conversion complete. WAV files saved in train_wavs directory.\")\n"
      ],
      "metadata": {
        "id": "_rHikXWqW_aL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list to store dictionaries\n",
        "audio_files = []\n",
        "text_sentences = train_df['sentence'].tolist()\n",
        "\n",
        "def process_audio(audio_name, sentence):\n",
        "    audio_path = os.path.join(train_wav_path, audio_name.replace(\".mp3\", \".wav\"))\n",
        "\n",
        "    audio_files.append(audio_path)\n",
        "    text_sentences(sentence)\n",
        "\n",
        "\n",
        "# Iterate through your dataset and call the function for each entry\n",
        "for index, row in train_df.iterrows():\n",
        "  try:\n",
        "    audio_name = row['path']\n",
        "    sentence = row['sentence']\n",
        "    process_audio(audio_name, sentence) # data in sentence paramenter is not working somehow\n",
        "  except:\n",
        "    pass"
      ],
      "metadata": {
        "id": "NmVNR3gbax37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_files[0]"
      ],
      "metadata": {
        "id": "NFo6zNTQhFgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_sentences[0]"
      ],
      "metadata": {
        "id": "tTDenhfMg_AV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text_sentences) == len(audio_files)"
      ],
      "metadata": {
        "id": "8lAhCFzkiO4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def path_to_spectrogram(path):\n",
        "    # spectrogram using stft\n",
        "    audio = tf.io.read_file(path)\n",
        "    audio, _ = tf.audio.decode_wav(audio, 1)\n",
        "    audio = tf.squeeze(audio, axis=-1)\n",
        "    stfts = tf.signal.stft(audio, frame_length=200, frame_step=80, fft_length=256)\n",
        "    x = tf.math.pow(tf.abs(stfts), 0.5)\n",
        "    # normalisation\n",
        "    means = tf.math.reduce_mean(x, 1, keepdims=True)\n",
        "    stddevs = tf.math.reduce_std(x, 1, keepdims=True)\n",
        "    x = x = (x - means) / (stddevs + 1e-8)\n",
        "    audio_len = tf.shape(x)[0]\n",
        "    # padding to 10 seconds\n",
        "    pad_len = 2754\n",
        "    paddings = tf.constant([[0, pad_len], [0, 0]])\n",
        "    x = tf.pad(x, paddings, \"CONSTANT\")[:pad_len, :]\n",
        "    return x"
      ],
      "metadata": {
        "id": "vkd_I1Y_cUAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "specto = path_to_spectrogram(audio_files[0])\n",
        "specto"
      ],
      "metadata": {
        "id": "_JlIVsHMdg8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VectorizeChar:\n",
        "    def __init__(self, max_len=50):\n",
        "        self.vocab = (\n",
        "            [\"-\", \"#\", \"<\", \">\"]\n",
        "            + [chr(i + 96) for i in range(1, 27)]\n",
        "            + [\" \", \".\", \",\", \"?\"]\n",
        "        )\n",
        "        self.max_len = max_len\n",
        "        self.char_to_idx = {}\n",
        "        for i, ch in enumerate(self.vocab):\n",
        "            self.char_to_idx[ch] = i\n",
        "\n",
        "    def __call__(self, text):\n",
        "        text = text.lower()\n",
        "        text = text[: self.max_len - 2]\n",
        "        text = \"<\" + text + \">\"\n",
        "        pad_len = self.max_len - len(text)\n",
        "        return [self.char_to_idx.get(ch, 1) for ch in text] + [0] * pad_len\n",
        "\n",
        "    def get_vocabulary(self):\n",
        "        return self.vocab"
      ],
      "metadata": {
        "id": "Ez6uP6qwe6iL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_target_len = 200\n",
        "vactorizer = VectorizeChar(max_target_len)\n",
        "print(\"vocab size\", len(vactorizer.get_vocabulary()))"
      ],
      "metadata": {
        "id": "TaIJ9qp-gWlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_text_ds(texts_list):\n",
        "    texts = texts_list\n",
        "    text_ds = [vactorizer(t) for t in texts]\n",
        "    text_ds = tf.data.Dataset.from_tensor_slices(text_ds)\n",
        "    return text_ds"
      ],
      "metadata": {
        "id": "IkpZ_XFmgaaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_audio_ds(audio_files_list):\n",
        "    flist = audio_files_list\n",
        "    audio_ds = tf.data.Dataset.from_tensor_slices(flist)\n",
        "    audio_ds = audio_ds.map(\n",
        "        path_to_spectrogram, num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "    return audio_ds"
      ],
      "metadata": {
        "id": "C_b0zQqnj0R0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tf_dataset(data, bs=4):\n",
        "    audio_ds = create_audio_ds(data)\n",
        "    text_ds = create_text_ds(data)\n",
        "    ds = tf.data.Dataset.zip((audio_ds, text_ds))\n",
        "    ds = ds.map(lambda x, y: {\"source\": x, \"target\": y})\n",
        "    ds = ds.batch(bs)\n",
        "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
        "    return ds"
      ],
      "metadata": {
        "id": "5g0qP151kRDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train test data\n",
        "train_size = .9\n",
        "split_idx = int(train_size * len(audio_files))\n",
        "\n",
        "train_audios = audio_files[:split_idx]\n",
        "test_audios = audio_files[split_idx:]\n",
        "\n",
        "train_texts = text_sentences[:split_idx]\n",
        "test_texts = text_sentences[split_idx:]"
      ],
      "metadata": {
        "id": "uevSZWcVleGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text_ds, test_text_ds = create_text_ds(train_texts), create_text_ds(test_texts)"
      ],
      "metadata": {
        "id": "wJScVBOWgxes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_audio_ds, test_audio_ds = create_audio_ds(train_audios), create_audio_ds(test_audios)"
      ],
      "metadata": {
        "id": "8c2eJ4wsjtdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tf_dataset(audio_ds, text_ds, bs=4):\n",
        "    ds = tf.data.Dataset.zip((audio_ds, text_ds))\n",
        "    ds = ds.map(lambda x, y: {\"source\": x, \"target\": y})\n",
        "    ds = ds.batch(bs)\n",
        "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
        "    return ds"
      ],
      "metadata": {
        "id": "J5cvei_GkKSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds, val_ds = create_tf_dataset(train_audio_ds, train_text_ds, bs=64), create_tf_dataset(test_audio_ds, test_text_ds, bs=4)"
      ],
      "metadata": {
        "id": "4YK6bJQLlD3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "id": "ITZHs-0ZklUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds"
      ],
      "metadata": {
        "id": "l8iuLuKlktGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U7pSJOv2pZfz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}